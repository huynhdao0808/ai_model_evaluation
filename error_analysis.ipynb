{
 "cells": [
  {
   "cell_type": "code",
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport numpy as np\nimport warnings\nimport json\nfrom pathlib import Path\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Import functions from error_analysis.py\nfrom error_analysis import crop_image, show_image_pairs, generate_confusion_matrices, load_config\n\n# Suppress all warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Display configuration for the notebook\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 50)\npd.set_option('display.width', 1000)"
  },
  {
   "cell_type": "code",
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": "model = \"result_rtmdet_0226\"\ndataset_version = \"dataset_v1\"  # Full folder name of the dataset version\n\n# Select the specific run to analyze (use the latest run folder by default)\nimport os\nfrom pathlib import Path\nmodel_path = f\"prediction/{model}\"\n# Get all run folders sorted by timestamp (latest first)\nrun_folders = sorted([f for f in os.listdir(model_path) if f.startswith(\"run_\")], reverse=True)\nif run_folders:\n    run_folder = run_folders[0]  # Use the latest run by default\n    print(f\"Using latest run: {run_folder}\")\nelse:\n    run_folder = \"run_latest\"\n    print(\"No run folders found. Using default name.\")\n\n# Path to the evaluation CSV file\nresult_file = f\"{model_path}/{run_folder}/{model}_evaluation.csv\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv(result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[df_eval['eval'] == \"TP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Optimize the confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[(df_eval['gt']=='impression') & (df_eval['eval']==\"TP\")].sort_values(\"confidence\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[(df_eval['gt']=='einriss') & (df_eval['eval']==\"TP\")]['confidence'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[df_eval.filename.str.contains('235117')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named df\n",
    "\n",
    "# Find rows that are duplicates based on 'gt', 'gt_location', and 'filename'\n",
    "duplicates = df_eval.duplicated(subset=['gt', 'gt_location', 'filename'], keep=False)\n",
    "\n",
    "# Separate the dataframe into rows that are duplicates and those that are not\n",
    "df_duplicates = df_eval[duplicates]\n",
    "df_non_duplicates = df_eval[~duplicates]\n",
    "\n",
    "# Drop rows where 'pred' is null in the duplicate rows\n",
    "df_duplicates = df_duplicates.dropna(subset=['pred'])\n",
    "\n",
    "# Combine the non-duplicate rows and the cleaned duplicate rows\n",
    "df_eval = pd.concat([df_non_duplicates, df_duplicates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[df_eval['filename'].str.contains(\"_915\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes\n",
    "df_eval_matrix = df_eval.copy()\n",
    "classes = [\"impression\", \"einriss\", \"abriss\", \"asperity\", \"ausseinriss\"]\n",
    "\n",
    "# Replace null values for 'gt' and 'pred' with 'None'\n",
    "df_eval_matrix['gt'] = df_eval_matrix['gt'].fillna('None')\n",
    "df_eval_matrix['pred'] = df_eval_matrix['pred'].fillna('None')\n",
    "\n",
    "# Ensure all labels in gt and pred are among the defined classes or 'None'\n",
    "valid_labels = set(classes + ['None'])\n",
    "# assert set(df_eval_matrix['gt']).issubset(valid_labels), \"Unexpected values in 'gt'\"\n",
    "# assert set(df_eval_matrix['pred']).issubset(valid_labels), \"Unexpected values in 'pred'\"\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(df_eval_matrix['gt'], df_eval_matrix['pred'], labels=classes + ['None'])\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes + ['None'])\n",
    "disp.plot(cmap=\"viridis\", xticks_rotation=\"vertical\")\n",
    "disp.ax_.set_title(\"Confusion Matrix\")\n",
    "disp.ax_.set_xlabel(\"Predicted Label\")\n",
    "disp.ax_.set_ylabel(\"Ground Truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": "# Confusion matrix in image level\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport os\n\n# Specify the directory for images\ndirectory = f'images/{dataset_version}'\n\n# Get the list of file names\nfile_names = os.listdir(directory)\n\n# Filter out directories, if needed\nfull_list = [f.split(\".\")[0] for f in file_names if os.path.isfile(os.path.join(directory, f))]\n\n# Get lists of rejected images (based on ground truth and predictions)\nground_truth_rejected = df_eval[df_eval['gt'].notnull()]['filename'].drop_duplicates().to_list()\npredicted_rejected = df_eval[df_eval['pred'].notnull()]['filename'].drop_duplicates().to_list()\n\n# Calculate true positives, false positives, true negatives, and false negatives\ntp = len(set(ground_truth_rejected) & set(predicted_rejected))\nfn = len(set(ground_truth_rejected) - set(predicted_rejected))\nfp = len(set(predicted_rejected) - set(ground_truth_rejected))\ntn = len(set(full_list) - set(ground_truth_rejected) - set(predicted_rejected))\n\n# Construct confusion matrix\ncm = np.array([[tp, fn],\n               [fp, tn]])\n\n# Display confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Rejected', 'Accepted'])\ndisp.plot(cmap='viridis')\n\n# Add metrics to the title\nprecision = tp / (tp + fp) if (tp + fp) > 0 else 0\nrecall = tp / (tp + fn) if (tp + fn) > 0 else 0\nf1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n\nplt.title(f'Confusion Matrix\\nPrecision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}')\nplt.show()\n\n# Print results\nprint(f\"Total images: {len(full_list)}\")\nprint(f\"Images with defects (from GT): {len(ground_truth_rejected)}\")\nprint(f\"Images with defects (predicted): {len(predicted_rejected)}\")\nprint(f\"True Positives: {tp}, False Positives: {fp}, False Negatives: {fn}, True Negatives: {tn}\")\nprint(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
  },
  {
   "cell_type": "code",
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\ndef crop_image(original_image):\n    offset = 20\n    gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n    threshold_value = np.mean(gray) + np.std(gray)\n    _, thresholded_image = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)\n\n    contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    if not contours:\n        print(\"No contours found!\")\n        return\n\n    largest_contour = max(contours, key=cv2.contourArea)\n    x, y, w, h = cv2.boundingRect(largest_contour)\n    x_crop = max(0, x - offset)\n    y_crop = max(0, y - offset)\n    w = min(original_image.shape[1] - x_crop, w + 2 * offset)\n    h = min(original_image.shape[0] - y_crop, h + 2 * offset)\n    cropped_image = original_image[y_crop:y_crop+h, x_crop:x_crop+w]\n    \n    return cropped_image \n    \ndef show_image_pairs(image_pairs, mode, def_name):\n    \"\"\"\n    Display multiple pairs of images side by side.\n    \n    :param image_pairs: List of tuples, where each tuple contains paths to two images (image1_path, image2_path).\n    \"\"\"\n    \n    for idx, (filename, img2_path, gt, pred) in enumerate(image_pairs):\n        # Read images\n        fig_each, axes_each = plt.subplots(nrows=1, ncols=2, figsize=(20, 2))\n        fig_each.suptitle(f\"{def_name} - {mode}\", fontsize=16)\n        \n        # Try to find the misdetection image in the current run folder\n        misdetections_path = f\"{model_path}/{run_folder}/misdetections\"\n        img1_path = None\n        \n        if os.path.exists(misdetections_path):\n            for file_name in os.listdir(misdetections_path):\n                if filename in file_name:  # Check if part_of_name is in file_name\n                    img1_path = os.path.join(misdetections_path, file_name)\n                    break\n        \n        # If not found in current run, try the model's general misdetection folder\n        if not img1_path:\n            model_misdetections = f\"prediction/{model}/misdetections\"\n            if os.path.exists(model_misdetections):\n                for file_name in os.listdir(model_misdetections):\n                    if filename in file_name:\n                        img1_path = os.path.join(model_misdetections, file_name)\n                        break\n        \n        # If still not found, use the original image\n        if not img1_path or not os.path.exists(img1_path):\n            print(f\"Warning: Misdetection image not found for {filename}, using original image\")\n            img1_path = img2_path\n            \n        # Check if the second image exists\n        if not os.path.exists(img2_path):\n            print(f\"Error: Image not found -> {img2_path}\")\n            continue\n            \n        # Load and process images\n        img1 = cv2.cvtColor(cv2.imread(img1_path), cv2.COLOR_BGR2RGB)\n        img1 = crop_image(img1)\n        img2 = cv2.cvtColor(cv2.imread(img2_path), cv2.COLOR_BGR2RGB)\n        \n        if mode == \"TP\":\n            img1 = cv2.cvtColor(cv2.imread(img2_path), cv2.COLOR_BGR2RGB)\n        \n        # Display the first image\n        axes_each[0].set_title(f\"{filename} {mode} {pred}\")\n        axes_each[0].imshow(img1)\n        \n        # Display the second image\n        axes_each[1].set_title(f\"Output\")\n        axes_each[1].imshow(img2)\n        \n        # Save the error pair image\n        error_pairs_dir = f\"{model_path}/{run_folder}/error_pairs\"\n        os.makedirs(error_pairs_dir, exist_ok=True)\n        \n        fig_each.savefig(f\"{error_pairs_dir}/{mode}_{def_name}_{Path(img2_path).name.split('.')[0]}.jpg\")\n    \n        plt.tight_layout(rect=[0, 0, 1, 0.98])\n        plt.show()"
  },
  {
   "cell_type": "code",
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": "def_names =  [ \"einriss\", \"abriss\", \"ausseinriss\", \"impression\", \"asperity\" ]\n# def_names =  [ \"abriss\"]\ntype = \"FN\" # FN, FP\n# modes = [\"merge\", \"wrong\", \"notdetect\"]\nmodes = [\"notdetect\"]\n\nfor def_name in def_names:\n    \n    for mode in modes:\n\n        if mode == \"merge\":\n            fil_df_eval = df_eval[(df_eval['gt']==def_name) & (df_eval['eval']==type) & (df_eval['pred'] == df_eval['gt'])]\n        elif mode == \"wrong\":\n            fil_df_eval = df_eval[(df_eval['gt']==def_name) & (df_eval['eval']==type) & (df_eval['pred'] != df_eval['gt']) & df_eval['pred'].notnull()]\n        elif mode == \"notdetect\":\n            fil_df_eval = df_eval[(df_eval['gt']==def_name) & (df_eval['eval']==type) & (df_eval['pred'].isnull())]\n            \n        if fil_df_eval.shape[0] != 0:\n            fil_df_eval['gt_path'] = f\"{model_path}/{run_folder}/image_unfilter_crop/\" + fil_df_eval['filename'] + \".bmp\"\n            fil_df_eval = fil_df_eval.sort_values(\"pred\")\n            image_pairs = list(zip(fil_df_eval['filename'], fil_df_eval['gt_path'], fil_df_eval['gt'], fil_df_eval['pred']))\n\n            # In notebook, we use show_plot=True to display the images interactively\n            show_image_pairs(image_pairs[:5], mode, def_name, model_path, run_folder, None, save_images=False, show_plot=True)"
  },
  {
   "cell_type": "code",
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": "# def_names =  [ \"einriss\", \"abriss\", \"ausseinriss\", \"impression\", \"asperity\" ]\ndef_names = ['abriss']\ntype = \"FP\" # FN, FP\n# modes = [\"wrong\", \"redundant\"]\nmodes = [ \"redundant\"]\n\nfor def_name in def_names:\n    for mode in modes:\n\n        if mode == \"wrong\":\n            fil_df_eval = df_eval[(df_eval['pred']==def_name) & (df_eval['eval']==type) & (df_eval['pred'] != df_eval['gt']) & df_eval['gt'].notnull()]\n        elif mode == \"redundant\":\n            fil_df_eval = df_eval[(df_eval['pred']==def_name) & (df_eval['eval']==type) & (df_eval['gt'].isnull())]\n            \n        if fil_df_eval.shape[0] != 0:\n            fil_df_eval['gt_path'] = f\"{model_path}/{run_folder}/image_unfilter_crop/\" + fil_df_eval['filename'] + \".bmp\"\n            fil_df_eval = fil_df_eval.sort_values(\"gt\")\n            image_pairs = list(zip(fil_df_eval['filename'], fil_df_eval['gt_path'], fil_df_eval['pred'], fil_df_eval['gt']))\n\n            # In notebook, we use show_plot=True to display the images interactively\n            show_image_pairs(image_pairs[:5], mode, def_name, model_path, run_folder, None, save_images=False, show_plot=True)"
  },
  {
   "cell_type": "code",
   "source": "# def_names =  [ \"einriss\", \"abriss\", \"ausseinriss\", \"impression\", \"asperity\" ]\ndef_names = ['abriss']\ntype = \"TP\"\nmodes = [\"TP\"]\n\nfor def_name in def_names:\n    for mode in modes:\n\n        fil_df_eval = df_eval[(df_eval['pred']==def_name) & (df_eval['eval']==type)]\n            \n        if fil_df_eval.shape[0] != 0:\n            fil_df_eval['gt_path'] = f\"{model_path}/{run_folder}/image_unfilter_crop/\" + fil_df_eval['filename'] + \".bmp\"\n            fil_df_eval = fil_df_eval.sort_values(\"gt\")\n            image_pairs = list(zip(fil_df_eval['filename'], fil_df_eval['gt_path'], fil_df_eval['pred'], fil_df_eval['gt']))\n\n            # In notebook, we use show_plot=True to display the images interactively\n            show_image_pairs(image_pairs[:5], mode, def_name, model_path, run_folder, None, save_images=False, show_plot=True)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the confusion matrix for each defect type\nplt.figure(figsize=(15, 12))\n\n# Extract data for all defect types\ndefect_data = {}\nfor defect in classes:\n    if defect in results:\n        metrics = results[defect]\n        tp = metrics.get('tp', 0)\n        fp = metrics.get('fp', 0)\n        fn = metrics.get('fn', 0)\n        tn = len(full_list) - (tp + fp + fn)  # Approximate TN\n        defect_data[defect] = {\n            'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn,\n            'precision': metrics.get('precision', 0),\n            'recall': metrics.get('recall', 0)\n        }\n\n# Plot individual confusion matrices\nfor i, defect in enumerate(classes):\n    if defect in defect_data:\n        data = defect_data[defect]\n        cm = np.array([[data['tp'], data['fn']], [data['fp'], data['tn']]])\n        \n        plt.subplot(2, 3, i+1)\n        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Defect', 'No Defect'])\n        disp.plot(cmap='viridis', ax=plt.gca())\n        \n        plt.title(f\"{defect.capitalize()}\\nPrecision: {data['precision']:.2f}, Recall: {data['recall']:.2f}\")\n        \nplt.tight_layout()\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}