{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"result_rtmdet_0226\"\n",
    "confidence = \"01\"\n",
    "result_file = model+\"_\"+str(confidence)+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv(result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[df_eval['eval'] == \"TP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Optimize the confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[(df_eval['gt']=='impression') & (df_eval['eval']==\"TP\")].sort_values(\"confidence\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[(df_eval['gt']=='einriss') & (df_eval['eval']==\"TP\")]['confidence'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[df_eval.filename.str.contains('235117')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named df\n",
    "\n",
    "# Find rows that are duplicates based on 'gt', 'gt_location', and 'filename'\n",
    "duplicates = df_eval.duplicated(subset=['gt', 'gt_location', 'filename'], keep=False)\n",
    "\n",
    "# Separate the dataframe into rows that are duplicates and those that are not\n",
    "df_duplicates = df_eval[duplicates]\n",
    "df_non_duplicates = df_eval[~duplicates]\n",
    "\n",
    "# Drop rows where 'pred' is null in the duplicate rows\n",
    "df_duplicates = df_duplicates.dropna(subset=['pred'])\n",
    "\n",
    "# Combine the non-duplicate rows and the cleaned duplicate rows\n",
    "df_eval = pd.concat([df_non_duplicates, df_duplicates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[df_eval['filename'].str.contains(\"_915\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes\n",
    "df_eval_matrix = df_eval.copy()\n",
    "classes = [\"impression\", \"einriss\", \"abriss\", \"asperity\", \"ausseinriss\"]\n",
    "\n",
    "# Replace null values for 'gt' and 'pred' with 'None'\n",
    "df_eval_matrix['gt'] = df_eval_matrix['gt'].fillna('None')\n",
    "df_eval_matrix['pred'] = df_eval_matrix['pred'].fillna('None')\n",
    "\n",
    "# Ensure all labels in gt and pred are among the defined classes or 'None'\n",
    "valid_labels = set(classes + ['None'])\n",
    "# assert set(df_eval_matrix['gt']).issubset(valid_labels), \"Unexpected values in 'gt'\"\n",
    "# assert set(df_eval_matrix['pred']).issubset(valid_labels), \"Unexpected values in 'pred'\"\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(df_eval_matrix['gt'], df_eval_matrix['pred'], labels=classes + ['None'])\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes + ['None'])\n",
    "disp.plot(cmap=\"viridis\", xticks_rotation=\"vertical\")\n",
    "disp.ax_.set_title(\"Confusion Matrix\")\n",
    "disp.ax_.set_xlabel(\"Predicted Label\")\n",
    "disp.ax_.set_ylabel(\"Ground Truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix in image level\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import os\n",
    "# Specify the directory\n",
    "directory = 'split//batch_1//images'\n",
    "\n",
    "# Get the list of file names\n",
    "file_names = os.listdir(directory)\n",
    "\n",
    "# Filter out directories, if needed\n",
    "full_list = [f.split(\".\")[0] for f in file_names if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# Example data\n",
    "ground_truth_rejected = df_eval[df_eval['gt'].notnull()]['filename'].drop_duplicates().to_list()\n",
    "predicted_rejected = df_eval[df_eval['pred'].notnull()]['filename'].drop_duplicates().to_list()\n",
    "\n",
    "# Calculate true positives, false positives, true negatives, and false negatives\n",
    "tp = len(set(ground_truth_rejected) & set(predicted_rejected))\n",
    "fn = len(set(ground_truth_rejected) - set(predicted_rejected))\n",
    "fp = len(set(predicted_rejected) - set(ground_truth_rejected))\n",
    "tn = len(set(full_list) - set(ground_truth_rejected) - set(predicted_rejected))\n",
    "\n",
    "# Construct confusion matrix\n",
    "cm = np.array([[tp, fn],\n",
    "               [fp, tn]])\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Rejected', 'Accepted'])\n",
    "disp.plot(cmap='viridis')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def crop_image(original_image):\n",
    "    offset = 20\n",
    "    gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "    threshold_value = np.mean(gray) + np.std(gray)\n",
    "    _, thresholded_image = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        print(\"No contours found!\")\n",
    "        return\n",
    "\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    x_crop = max(0, x - offset)\n",
    "    y_crop = max(0, y - offset)\n",
    "    w = min(original_image.shape[1] - x_crop, w + 2 * offset)\n",
    "    h = min(original_image.shape[0] - y_crop, h + 2 * offset)\n",
    "    cropped_image = original_image[y_crop:y_crop+h, x_crop:x_crop+w]\n",
    "    \n",
    "    return cropped_image \n",
    "    \n",
    "def show_image_pairs(image_pairs, mode, def_name):\n",
    "    \"\"\"\n",
    "    Display multiple pairs of images side by side.\n",
    "    \n",
    "    :param image_pairs: List of tuples, where each tuple contains paths to two images (image1_path, image2_path).\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx, (filename, img2_path, gt, pred) in enumerate(image_pairs):\n",
    "        # Read images\n",
    "        fig_each, axes_each = plt.subplots(nrows=1, ncols=2, figsize=(20, 2))\n",
    "        fig_each.suptitle(f\"{def_name} - {mode}\", fontsize=16)\n",
    "        \n",
    "        for file_name in os.listdir(\"split\\\\batch_1\\\\\" + model +\"\\\\\" +str(confidence)+ \"\\\\misdetections\\\\\"):\n",
    "            if filename in file_name:  # Check if part_of_name is in file_name\n",
    "                img1_path = os.path.join(\"split\\\\batch_1\\\\\" + model + \"\\\\\" +str(confidence)+ \"\\\\misdetections\\\\\", file_name)\n",
    "            else:\n",
    "                pass\n",
    "#                 img1_path = img2_path\n",
    "\n",
    "        if not os.path.exists(img1_path):\n",
    "            print(f\"Error: File not found -> {img1_path}\")\n",
    "        if not os.path.exists(img2_path):\n",
    "            print(f\"Error: File not found -> {img2_path}\")\n",
    "        img1 = cv2.cvtColor(cv2.imread(img1_path), cv2.COLOR_BGR2RGB)\n",
    "        img1 = crop_image(img1)\n",
    "        img2 = cv2.cvtColor(cv2.imread(img2_path), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if mode == \"TP\":\n",
    "            img1 = cv2.cvtColor(cv2.imread(img2_path), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display the first image\n",
    "        axes_each[0].set_title(f\"{filename} {mode} {pred}\")\n",
    "        axes_each[0].imshow(img1)\n",
    "        \n",
    "        # Display the second image\n",
    "        axes_each[1].set_title(f\"Output\")\n",
    "        axes_each[1].imshow(img2)\n",
    "        if not os.path.exists(\"split\\\\batch_1\\\\\" + model + \"\\\\\" +str(confidence)+ \"\\\\error_pairs\"):\n",
    "            os.makedirs(\"split\\\\batch_1\\\\\" + model + \"\\\\\" +str(confidence)+ \"\\\\error_pairs\")\n",
    "        \n",
    "        fig_each.savefig(\"split\\\\batch_1\\\\\" + model + \"\\\\\" +str(confidence)+ \"\\\\error_pairs\\\\\"+mode+\"_\"+def_name+\"_\"+Path(img2_path).name.split(\".\")[0]+'.jpg')\n",
    "    \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_names =  [ \"einriss\", \"abriss\", \"ausseinriss\", \"impression\", \"asperity\" ]\n",
    "# def_names =  [ \"abriss\"]\n",
    "type = \"FN\" # FN, FP\n",
    "# modes = [\"merge\", \"wrong\", \"notdetect\"]\n",
    "modes = [\"notdetect\"]\n",
    "\n",
    "for def_name in def_names:\n",
    "    \n",
    "    for mode in modes:\n",
    "\n",
    "        if mode == \"merge\":\n",
    "            fil_df_eval = df_eval[(df_eval['gt']==def_name) & (df_eval['eval']==type) & (df_eval['pred'] == df_eval['gt'])]\n",
    "        elif mode == \"wrong\":\n",
    "            fil_df_eval = df_eval[(df_eval['gt']==def_name) & (df_eval['eval']==type) & (df_eval['pred'] != df_eval['gt']) & df_eval['pred'].notnull()]\n",
    "        elif mode == \"notdetect\":\n",
    "            fil_df_eval = df_eval[(df_eval['gt']==def_name) & (df_eval['eval']==type) & (df_eval['pred'].isnull())]\n",
    "            \n",
    "        if fil_df_eval.shape[0] != 0:\n",
    "            # fil_df_eval['gt_path'] = \"split\\\\batch_1\\\\\" + model + \"\\\\\" + str(confidence) +  \"\\\\images\\\\\" + fil_df_eval['filename'] + \".bmp\"\n",
    "            fil_df_eval['gt_path'] = \"split\\\\batch_1\\\\\" + model + \"\\\\\" + str(confidence) +  \"\\\\image_unfilter_crop\\\\\" + fil_df_eval['filename'] + \".bmp\"\n",
    "            # fil_df_eval['gt_path'] = \"split\\\\batch_1\\\\images_crop\\\\\"+ fil_df_eval['filename'] + \".jpg\"\n",
    "            fil_df_eval = fil_df_eval.sort_values(\"pred\")\n",
    "            image_pairs = list(zip(fil_df_eval['filename'], fil_df_eval['gt_path'], fil_df_eval['gt'], fil_df_eval['pred']))\n",
    "\n",
    "            show_image_pairs(image_pairs, mode, def_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def_names =  [ \"einriss\", \"abriss\", \"ausseinriss\", \"impression\", \"asperity\" ]\n",
    "def_names = ['abriss']\n",
    "type = \"FP\" # FN, FP\n",
    "# modes = [\"wrong\", \"redundant\"]\n",
    "modes = [ \"redundant\"]\n",
    "\n",
    "for def_name in def_names:\n",
    "    for mode in modes:\n",
    "\n",
    "        if mode == \"wrong\":\n",
    "            fil_df_eval = df_eval[(df_eval['pred']==def_name) & (df_eval['eval']==type) & (df_eval['pred'] != df_eval['gt']) & df_eval['gt'].notnull()]\n",
    "        elif mode == \"redundant\":\n",
    "            fil_df_eval = df_eval[(df_eval['pred']==def_name) & (df_eval['eval']==type) & (df_eval['gt'].isnull())]\n",
    "            \n",
    "        if fil_df_eval.shape[0] != 0:\n",
    "            fil_df_eval['gt_path'] = \"split\\\\batch_1\\\\\"+ model +\"\\\\\"+ confidence +\"\\\\image_unfilter_crop\\\\\" + fil_df_eval['filename'] + \".bmp\"\n",
    "            fil_df_eval = fil_df_eval.sort_values(\"gt\")\n",
    "            image_pairs = list(zip(fil_df_eval['filename'], fil_df_eval['gt_path'], fil_df_eval['pred'], fil_df_eval['gt']))\n",
    "\n",
    "            show_image_pairs(image_pairs, mode, def_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def_names =  [ \"einriss\", \"abriss\", \"ausseinriss\", \"impression\", \"asperity\" ]\n",
    "def_names = ['abriss']\n",
    "type = \"TP\"\n",
    "modes = [\"TP\"]\n",
    "\n",
    "for def_name in def_names:\n",
    "    for mode in modes:\n",
    "\n",
    "        fil_df_eval = df_eval[(df_eval['pred']==def_name) & (df_eval['eval']==type)]\n",
    "            \n",
    "        if fil_df_eval.shape[0] != 0:\n",
    "            fil_df_eval['gt_path'] = \"split\\\\batch_1\\\\\"+ model +\"\\\\\"+ confidence +\"\\\\images_unfilter_crop\\\\\" + fil_df_eval['filename'] + \".bmp\"\n",
    "            fil_df_eval = fil_df_eval.sort_values(\"gt\")\n",
    "            image_pairs = list(zip(fil_df_eval['filename'], fil_df_eval['gt_path'], fil_df_eval['pred'], fil_df_eval['gt']))\n",
    "\n",
    "            show_image_pairs(image_pairs, mode, def_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
